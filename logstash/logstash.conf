# input Defines where Logstash gets its data from
# This defines two input sources:
# - TCP input on port 5000: Accepts raw log data over TCP. This is useful for custom log shippers or apps that send logs directly.
# - Beats input on port 5001: Accepts logs from Filebeat or other Elastic Beats agents. Filebeat is commonly used to ship logs from servers to Logstash.

input {
  tcp {
    port => 5000
  }
  beats {
    port => 5001
  }
}

# filter Processes and transforms the data.
# This tells Logstash to treat the incoming message field as a JSON string and parse it into structured fields.
# - If your logs are already in JSON format, this filter extracts key-value pairs.
# - If the message field isnâ€™t valid JSON, this step will fail silently unless you add error handling.

filter {
  json {
    source => "message"
  }
}

# This sends the processed logs to two destinations:
# - Elasticsearch:
# - Connects to the Elasticsearch service at elasticsearch:9200.
# - routing logs from different microservices into separate Elasticsearch indices is a smart move for clarity, performance, and retention control. 
# - %{[service]} pulls the value from the service field in the log. We have added this field as a part of winston logger
# - %{+YYYY.MM.dd} appends the date from the @timestamp field
# - stdout:
# - Prints the logs to the console (useful for debugging or local development).

output {
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    # index => "app-%{+YYYY.MM.dd}"
    index => "%{[service_name]}-%{+YYYY.MM.dd}"
  }
  stdout { codec => rubydebug }
}